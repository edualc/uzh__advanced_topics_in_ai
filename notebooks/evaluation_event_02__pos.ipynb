{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.namespace import Namespace, RDF, RDFS, XSD\n",
    "from rdflib.term import URIRef, Literal\n",
    "import csv\n",
    "import rdflib\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'jupyterlab+svg'\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from speakeasypy import Speakeasy, Chatroom\n",
    "from typing import List\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "from thefuzz import fuzz,process\n",
    "import editdistance\n",
    "import itertools\n",
    "\n",
    "import jsonpickle\n",
    "# NOTE: You might have to download a few things for nltk to work properly\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import Tree\n",
    "\n",
    "# NOTE: You might have to download the en_core_web_sm model for this to work\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/claude/development/uzh__advanced_topics_in_ai'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf60bffe633ae49fd9f5d5ed050e3f115 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse('data/14_graph.nt', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embeddings\n",
    "entity_emb = np.load('data/ddis-graph-embeddings/entity_embeds.npy')\n",
    "relation_emb = np.load('data/ddis-graph-embeddings/relation_embeds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dictionaries\n",
    "with open('data/ddis-graph-embeddings/entity_ids.del', 'r') as ifile:\n",
    "    ent2id = {str(rdflib.term.URIRef(ent)): int(idx) for idx, ent in csv.reader(ifile, delimiter='\\t')}\n",
    "    id2ent = {v: k for k, v in ent2id.items()}\n",
    "with open('data/ddis-graph-embeddings/relation_ids.del', 'r') as ifile:\n",
    "    rel2id = {str(rdflib.term.URIRef(rel)): int(idx) for idx, rel in csv.reader(ifile, delimiter='\\t')}\n",
    "    id2rel = {v: k for k, v in rel2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2lbl = {str(ent): str(lbl) for ent, lbl in g.subject_objects(RDFS.label)}\n",
    "lbl2ent = {lbl: ent for ent, lbl in ent2lbl.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefixes used in the graph\n",
    "WD = Namespace('http://www.wikidata.org/entity/')\n",
    "WDT = Namespace('http://www.wikidata.org/prop/direct/')\n",
    "SCHEMA = Namespace('http://schema.org/')\n",
    "DDIS = Namespace('http://ddis.ch/atai/')\n",
    "RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes(g):\n",
    "    nodes = {}\n",
    "    query =\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "    SELECT ?lbl WHERE {{\n",
    "        <{}> rdfs:label ?lbl .\n",
    "        FILTER(LANG(?lbl) = \"en\").\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    graph_entities = set(g.subjects(unique=True)) | {s for s in g.objects(unique=True) if isinstance(s, URIRef)}\n",
    "    for node in graph_entities:\n",
    "        entity = node.toPython()\n",
    "        if isinstance(node, URIRef):            \n",
    "            qres = g.query(query.format(entity))\n",
    "            for row in qres:\n",
    "                answer = row.lbl\n",
    "            \n",
    "            nodes[str(answer)] = entity\n",
    "    return nodes\n",
    "\n",
    "def extract_predicates(g):\n",
    "    query =\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "\n",
    "    SELECT ?lbl WHERE {{\n",
    "        <{}> rdfs:label ?lbl .\n",
    "        FILTER(LANG(?lbl) = \"en\").\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    predicates = {}\n",
    "\n",
    "    graph_predicates = set(g.predicates(unique=True))\n",
    "    for predicate in graph_predicates:\n",
    "        predicate_ = predicate.toPython()       \n",
    "        qres = g.query(query.format(predicate_))\n",
    "        for row in qres:\n",
    "            answer = row.lbl\n",
    "        \n",
    "        predicates[str(answer)] = predicate_\n",
    "\n",
    "    return predicates\n",
    "\n",
    "# make variables for the nodes and predicates path\n",
    "nodes_path = 'data/processed/nodes.json'\n",
    "predicates_path = 'data/processed/predicates.json'\n",
    "\n",
    "# check indiviudally if the files exist and if so load them\n",
    "if os.path.exists(nodes_path):\n",
    "    with open(nodes_path, 'r') as ifile:\n",
    "        nodes = jsonpickle.decode(ifile.read())\n",
    "else:\n",
    "    nodes = extract_nodes(g)\n",
    "    with open(nodes_path, 'w') as ofile:\n",
    "        ofile.write(jsonpickle.encode(nodes))\n",
    "\n",
    "if os.path.exists(predicates_path):\n",
    "    with open(predicates_path, 'r') as ifile:\n",
    "        predicates = jsonpickle.decode(ifile.read())\n",
    "else:\n",
    "    predicates = extract_predicates(g)\n",
    "    with open(predicates_path, 'w') as ofile:\n",
    "        ofile.write(jsonpickle.encode(predicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_QUESTIONS = [\n",
    "    \"What is the genre of Good Neighbors?\",\n",
    "    'Who directed Apocalypse Now?',\n",
    "    \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\",\n",
    "    \"Who is the screenwriter of The Masked Gang: Cyprus?\",\n",
    "    'When was The Godfather released?',\n",
    "    \"Who is the producer of Inception?\",\n",
    "    \"Who composed the soundtrack for Jurassic Park?\",\n",
    "    \"When was Pulp Fiction released?\",\n",
    "    \"Who played the lead role in The Matrix?\",\n",
    "    \"Who directed Blade Runner 2049?\",\n",
    "    \"What is the running time of The Shawshank Redemption?\",\n",
    "    \"Who was the cinematographer for Mad Max: Fury Road?\",\n",
    "    \"When did Titanic premiere?\",\n",
    "    \"Who wrote the screenplay for The Social Network?\",\n",
    "    \"What is the box office gross of Avatar?\",\n",
    "    \"Who edited the movie Parasite?\",\n",
    "    \"What is the budget of Halloween?\",\n",
    "    \"Who starred as the main character in Forrest Gump?\",\n",
    "    \"When was Interstellar first released?\",\n",
    "    \"Who is the production designer of Dune (2021)?\",\n",
    "    \"Who is the production designer of Dune?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(question):\n",
    "    doc = nlp(question)\n",
    "    displacy.render(doc, style='dep', jupyter=True)\n",
    "\n",
    "# print_tree(TEST_QUESTIONS[2])\n",
    "# print_tree(\"Who wrote the screenplay for The Social Network?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entity_phrase__rec(entity, preps_to_split, entities=list()):\n",
    "    if entity not in entities:\n",
    "        entities.append(entity)\n",
    "    for child in entity.children:\n",
    "        if child.dep_ == 'prep' and child in preps_to_split:\n",
    "            continue\n",
    "        entities = build_entity_phrase__rec(child, preps_to_split, entities)\n",
    "    return entities\n",
    "\n",
    "def build_entity_phrase(entity, preps_to_split):\n",
    "    entities = build_entity_phrase__rec(entity, preps_to_split)\n",
    "\n",
    "    tmp = []\n",
    "    # print(list(entity.subtree))\n",
    "    for token in entity.subtree:\n",
    "        if token in entities:\n",
    "            tmp.append(token)\n",
    "    \n",
    "    if tmp[0].text == 'the':\n",
    "        tmp = tmp[1:]\n",
    "\n",
    "    return ' '.join([token.text for token in tmp]).replace(' :', ':')\n",
    "\n",
    "def check_for_child_prep_pobj(child, entity_nodes, preps_to_split):\n",
    "    for subchild in child.children:\n",
    "        if subchild.dep_ == 'prep':\n",
    "            preps_to_split.append(subchild)\n",
    "\n",
    "            for subsubchild in subchild.children:\n",
    "                if subsubchild.dep_ == 'pobj':\n",
    "                    entity_nodes.append(subsubchild)\n",
    "                    entity_nodes, preps_to_split = check_for_child_prep_pobj(subsubchild, entity_nodes, preps_to_split)\n",
    "    return entity_nodes, preps_to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'released': {'type': 'VERB', 'matches': []}, 'The Godfather': {'type': None, 'matches': []}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"59f6ea43c8924c99bd1707d6198d5dfc-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Who</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">directed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Apocalypse</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Now?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-59f6ea43c8924c99bd1707d6198d5dfc-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-59f6ea43c8924c99bd1707d6198d5dfc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-59f6ea43c8924c99bd1707d6198d5dfc-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-59f6ea43c8924c99bd1707d6198d5dfc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-59f6ea43c8924c99bd1707d6198d5dfc-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-59f6ea43c8924c99bd1707d6198d5dfc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# question = \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\"   #1  ***\n",
    "# question = \"Who directed Apocalypse Now?\"                                         #2  ***\n",
    "# question = \"Who directed the movie Apocalypse Now?\"                               #2b ***\n",
    "question = \"When was The Godfather released?\"                                     #3  ***\n",
    "# question = \"Who composed the soundtrack for Jurassic Park?\"                       #4  ***\n",
    "# question = \"Who played the lead role in The Matrix?\"                              #5  ***\n",
    "# question = \"What is the running time of The Lord of the Rings?\"                   #6  ***\n",
    "# question = \"Who starred as the main character in Forrest Gump?\"                   #7  ***\n",
    "# question = \"When was Interstellar first released?\"                                #8  ***\n",
    "# question = \"What is the budget of Halloween?\"                                     #9  ***\n",
    "# question = \"Who wrote the screenplay for The Social Network?\"                     #10 ***\n",
    "\n",
    "\n",
    "def parse_question(question):\n",
    "    doc = nlp(question)\n",
    "    sent = list(doc.sents)[0]\n",
    "\n",
    "    root_type = sent.root.pos_\n",
    "    # print(f\"Root Type: {root_type}\")\n",
    "\n",
    "    entity_nodes = []\n",
    "    preps_to_split = []\n",
    "\n",
    "\n",
    "    if root_type == 'AUX':\n",
    "        for child in sent.root.children:\n",
    "            if child.dep_ == 'nsubj':\n",
    "                entity_nodes.append(child)\n",
    "                entity_nodes, preps_to_split = check_for_child_prep_pobj(child, entity_nodes, preps_to_split)\n",
    "\n",
    "\n",
    "    elif root_type == 'VERB':\n",
    "        for child in sent.root.children:\n",
    "            if child.dep_ == 'dobj':\n",
    "                entity_nodes.append(child)\n",
    "                entity_nodes, preps_to_split = check_for_child_prep_pobj(child, entity_nodes, preps_to_split)\n",
    "\n",
    "            elif child.dep_ == 'prep':\n",
    "                preps_to_split.append(child)\n",
    "\n",
    "                for subchild in child.children:\n",
    "                    if subchild.dep_ == 'pobj':\n",
    "                        entity_nodes.append(subchild)\n",
    "                        entity_nodes, preps_to_split = check_for_child_prep_pobj(subchild, entity_nodes, preps_to_split)\n",
    "\n",
    "            elif child.dep_ == 'nsubjpass':\n",
    "                entity_nodes.append(child)\n",
    "                entity_nodes, preps_to_split = check_for_child_prep_pobj(child, entity_nodes, preps_to_split)\n",
    "            \n",
    "            elif child.dep_ == 'nsubj':\n",
    "                if child.pos_ != 'PRON':\n",
    "                    entity_nodes.append(child)\n",
    "                    entity_nodes, preps_to_split = check_for_child_prep_pobj(child, entity_nodes, preps_to_split)\n",
    "\n",
    "\n",
    "    # print(entity_nodes)\n",
    "    entities = dict()\n",
    "    if root_type == 'VERB':\n",
    "        entities[sent.root.text] = { 'type': 'VERB', 'matches': [] }\n",
    "    for node in entity_nodes:\n",
    "        phrase = build_entity_phrase(node, preps_to_split)\n",
    "        entities[phrase] = { 'type': None, 'matches': [] }\n",
    "            \n",
    "    \n",
    "    return entities\n",
    "\n",
    "print(parse_question(question))\n",
    "print_tree(TEST_QUESTIONS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the genre of Good Neighbors?\n",
      "\t {'genre': {'type': None, 'matches': []}, 'Good Neighbors': {'type': None, 'matches': []}}\n",
      "Who directed Apocalypse Now?\n",
      "\t {'directed': {'type': 'VERB', 'matches': []}, 'Apocalypse': {'type': None, 'matches': []}}\n",
      "Who is the director of Star Wars: Episode VI - Return of the Jedi?\n",
      "\t {'director': {'type': None, 'matches': []}, 'Star Wars: Episode VI - Return of the Jedi': {'type': None, 'matches': []}}\n",
      "Who is the screenwriter of The Masked Gang: Cyprus?\n",
      "\t {'screenwriter': {'type': None, 'matches': []}, 'The Masked Gang: Cyprus': {'type': None, 'matches': []}}\n",
      "When was The Godfather released?\n",
      "\t {'released': {'type': 'VERB', 'matches': []}, 'The Godfather': {'type': None, 'matches': []}}\n",
      "Who is the producer of Inception?\n",
      "\t {'producer': {'type': None, 'matches': []}, 'Inception': {'type': None, 'matches': []}}\n",
      "Who composed the soundtrack for Jurassic Park?\n",
      "\t {'composed': {'type': 'VERB', 'matches': []}, 'soundtrack': {'type': None, 'matches': []}, 'Jurassic Park': {'type': None, 'matches': []}}\n",
      "When was Pulp Fiction released?\n",
      "\t {'released': {'type': 'VERB', 'matches': []}, 'Pulp Fiction': {'type': None, 'matches': []}}\n",
      "Who played the lead role in The Matrix?\n",
      "\t {'played': {'type': 'VERB', 'matches': []}, 'lead role': {'type': None, 'matches': []}, 'The Matrix': {'type': None, 'matches': []}}\n",
      "Who directed Blade Runner 2049?\n",
      "\t {'directed': {'type': 'VERB', 'matches': []}, 'Blade Runner 2049': {'type': None, 'matches': []}}\n",
      "What is the running time of The Shawshank Redemption?\n",
      "\t {'running time': {'type': None, 'matches': []}, 'The Shawshank Redemption': {'type': None, 'matches': []}}\n",
      "Who was the cinematographer for Mad Max: Fury Road?\n",
      "\t {'cinematographer': {'type': None, 'matches': []}, 'Mad Max: Fury Road': {'type': None, 'matches': []}}\n",
      "When did Titanic premiere?\n",
      "\t {'did': {'type': 'VERB', 'matches': []}, 'Titanic premiere': {'type': None, 'matches': []}}\n",
      "Who wrote the screenplay for The Social Network?\n",
      "\t {'wrote': {'type': 'VERB', 'matches': []}, 'screenplay': {'type': None, 'matches': []}, 'The Social Network': {'type': None, 'matches': []}}\n",
      "What is the box office gross of Avatar?\n",
      "\t {'box office gross': {'type': None, 'matches': []}, 'Avatar': {'type': None, 'matches': []}}\n",
      "Who edited the movie Parasite?\n",
      "\t {'edited': {'type': 'VERB', 'matches': []}, 'movie Parasite': {'type': None, 'matches': []}}\n",
      "What is the budget of Halloween?\n",
      "\t {'budget': {'type': None, 'matches': []}, 'Halloween': {'type': None, 'matches': []}}\n",
      "Who starred as the main character in Forrest Gump?\n",
      "\t {'starred': {'type': 'VERB', 'matches': []}, 'main character': {'type': None, 'matches': []}, 'Forrest Gump': {'type': None, 'matches': []}}\n",
      "When was Interstellar first released?\n",
      "\t {'released': {'type': 'VERB', 'matches': []}, 'Interstellar': {'type': None, 'matches': []}}\n",
      "Who is the production designer of Dune (2021)?\n",
      "\t {'production designer': {'type': None, 'matches': []}, 'Dune ( 2021': {'type': None, 'matches': []}}\n",
      "Who is the production designer of Dune?\n",
      "\t {'production designer': {'type': None, 'matches': []}, 'Dune': {'type': None, 'matches': []}}\n"
     ]
    }
   ],
   "source": [
    "for question in TEST_QUESTIONS:\n",
    "    print(question)\n",
    "    print('\\t', parse_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "WN_NOUN = 'n'\n",
    "WN_VERB = 'v'\n",
    "WN_ADJECTIVE = 'a'\n",
    "WN_ADJECTIVE_SATELLITE = 's'\n",
    "WN_ADVERB = 'r'\n",
    "\n",
    "\n",
    "def convert(input, from_pos, to_pos):    \n",
    "    \"\"\" Transform words given from/to POS tags \"\"\"\n",
    "    words,temp_word_list=[],[]\n",
    "    for index,word in enumerate(input.split(\" \")):\n",
    "        synsets = wn.synsets(word, pos=from_pos)\n",
    "\n",
    "        # Word not found\n",
    "        if not synsets:\n",
    "            if len(words)==0:\n",
    "                words.append((word,1.0))\n",
    "            else:\n",
    "                words =[(w+\" \"+word, p) for w,p in words]\n",
    "        else:\n",
    "            # Get all lemmas of the word (consider 'a'and 's' equivalent)\n",
    "            lemmas = []\n",
    "            for s in synsets:\n",
    "                for l in s.lemmas():\n",
    "                    if s.name().split('.')[1] == from_pos or from_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE) and s.name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE):\n",
    "                        lemmas += [l]\n",
    "\n",
    "            # Get related forms\n",
    "            derivationally_related_forms = [(l, l.derivationally_related_forms()) for l in lemmas]\n",
    "            # filter only the desired pos (consider 'a' and 's' equivalent)\n",
    "            related_noun_lemmas = []\n",
    "\n",
    "            for drf in derivationally_related_forms:\n",
    "                if from_pos == \"n\":\n",
    "                    related_noun_lemmas += [drf[0]]\n",
    "                else:\n",
    "                    for l in drf[1]:\n",
    "                        if l.synset().name().split('.')[1] == to_pos or to_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE) and l.synset().name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE):\n",
    "                            related_noun_lemmas += [l]\n",
    "\n",
    "            # Extract the words from the lemmas\n",
    "            temp_word_list=[l.name() for l in related_noun_lemmas]\n",
    "            temp_word_list = [(w, float(temp_word_list.count(w)) / len(temp_word_list)) for w in set(temp_word_list)]\n",
    "\n",
    "            # Take all the combinations for synonyms of different words\n",
    "            # Build the result in the form of a list containing tuples (word, probability)\n",
    "            if len(words)==0:\n",
    "                words=temp_word_list\n",
    "            else:\n",
    "                words =[(w_b+\" \"+w_t, p_b*p_t) for w_b,p_b in words for w_t,p_t in temp_word_list]\n",
    "                words.sort(key=lambda w:-w[1])\n",
    "\n",
    "    # return all the possibilities sorted by probability\n",
    "    return words\n",
    "\n",
    "# sorted(convert('played', WN_VERB, WN_NOUN), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_query(item_iri):\n",
    "    return \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "    SELECT ?lbl WHERE {{\n",
    "        <{}> rdfs:label ?lbl .\n",
    "        FILTER(LANG(?lbl) = \"en\").\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\".format(item_iri)\n",
    "\n",
    "def who_query(item_iri, predicate_iri):\n",
    "    return \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "    SELECT ?query WHERE {{\n",
    "        <{}> <{}> ?person .\n",
    "        ?person rdfs:label ?query .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\".format(item_iri, predicate_iri)\n",
    "\n",
    "def when_query(item_iri, predicate_iri):\n",
    "    return \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "    SELECT ?query WHERE {{\n",
    "        <{}> <{}> ?query .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\".format(item_iri, predicate_iri)\n",
    "\n",
    "def what_query(item_iri, predicate_iri):\n",
    "    return \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "    SELECT ?query WHERE {{\n",
    "        <{}> <{}> ?query .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\".format(item_iri, predicate_iri)\n",
    "\n",
    "def what_query__with_label(item_iri, predicate_iri):\n",
    "    return \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "    SELECT ?query WHERE {{\n",
    "        <{}> <{}> ?item .\n",
    "        ?item rdfs:label ?query .\n",
    "        FILTER(LANG(?query) = \"en\").\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\".format(item_iri, predicate_iri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_factual(question):\n",
    "    if 'who' in question.lower().split(' '):\n",
    "        question_type = 'who'\n",
    "    elif 'when' in question.lower().split(' '):\n",
    "        question_type = 'when'\n",
    "    elif 'what' in question.lower().split(' '):\n",
    "        question_type = 'what'\n",
    "    else:\n",
    "        question_type = 'unknown'\n",
    "\n",
    "    # get all possible entities from parsing the question\n",
    "    # ============================================================\n",
    "    #\n",
    "    parsed_dict = parse_question(question)\n",
    "    # print(parsed_dict)\n",
    "\n",
    "    # look up any possible match in the predicates/nodes\n",
    "    # ============================================================\n",
    "    #\n",
    "    def lookup_item(label, nodes, predicates):\n",
    "        matches = []\n",
    "        if label in nodes.keys():\n",
    "            matches.append(nodes[label])\n",
    "        if label in predicates.keys():\n",
    "            matches.append(predicates[label])\n",
    "        return matches\n",
    "\n",
    "    for entity in parsed_dict.keys():\n",
    "        # in case of verbs, we want to check for synonyms, e.g.\n",
    "        # \"played\" -> \"actor\"\n",
    "        #\n",
    "        if parsed_dict[entity]['type'] == 'VERB':\n",
    "            # check synonyms based on noun form of the verb\n",
    "            noun_forms = convert(entity, WN_VERB, WN_NOUN)\n",
    "\n",
    "            if question_type == 'when':\n",
    "                noun_forms.extend([(f\"{noun[0]} date\",0) for noun in noun_forms])\n",
    "                # print(noun_forms)\n",
    "\n",
    "            candidate_synonyms = list(filter(lambda x: x in nodes.keys(), [x[0] for x in noun_forms]))\n",
    "            candidate_synonyms.append(entity)\n",
    "\n",
    "            tmp = []\n",
    "            for candidate in candidate_synonyms:\n",
    "                if candidate == 'star':\n",
    "                    tmp.extend(lookup_item('cast member', nodes, predicates))\n",
    "                tmp.extend(lookup_item(candidate, nodes, predicates))\n",
    "                \n",
    "            parsed_dict[entity]['matches'] = tmp\n",
    "\n",
    "        else:\n",
    "            parsed_dict[entity]['matches'].extend(lookup_item(entity, nodes, predicates))\n",
    "\n",
    "        parsed_dict[entity]['matches'] = list(set(parsed_dict[entity]['matches']))\n",
    "    print(parsed_dict)\n",
    "\n",
    "    # build query based on question word\n",
    "    # ============================================================\n",
    "    #\n",
    "    possible_predicates = set()\n",
    "    possible_items = set()\n",
    "\n",
    "    for phrase in parsed_dict.keys():\n",
    "        for match in parsed_dict[phrase]['matches']:\n",
    "            identifier = match.split('/')[-1]\n",
    "\n",
    "            if identifier.startswith('P'):\n",
    "                possible_predicates.add(f\"http://www.wikidata.org/prop/direct/{identifier}\")\n",
    "            elif identifier.startswith('Q'):\n",
    "                possible_items.add(f\"http://www.wikidata.org/entity/{identifier}\")\n",
    "    print(f\"Identified Items: {possible_items}\")\n",
    "    print(f\"Identified Predicates: {possible_predicates}\")\n",
    "    \n",
    "    # Build possible queries\n",
    "    # ============================================================\n",
    "    #\n",
    "    if question_type == 'who':\n",
    "        queries = []\n",
    "        for item in possible_items:\n",
    "            for predicate in possible_predicates:\n",
    "                queries.append(who_query(item, predicate))\n",
    "\n",
    "    elif question_type == 'when':\n",
    "        queries = []\n",
    "        for item in possible_items:\n",
    "            for predicate in possible_predicates:\n",
    "                queries.append(when_query(item, predicate))\n",
    "\n",
    "    elif question_type == 'what':\n",
    "        queries = []\n",
    "        for item in possible_items:\n",
    "            for predicate in possible_predicates:\n",
    "                queries.append(what_query(item, predicate))\n",
    "                queries.append(what_query__with_label(item, predicate))\n",
    "\n",
    "    else:\n",
    "        print('UNKNOWN QUESTION TYPE')\n",
    "\n",
    "\n",
    "    # Execute queries\n",
    "    # ============================================================\n",
    "    #\n",
    "    query_answered = False\n",
    "    for query in queries:\n",
    "        # print(query)\n",
    "        res = g.query(query)\n",
    "        \n",
    "        if len(res) == 0:\n",
    "            continue\n",
    "\n",
    "        for row in res:\n",
    "            result = row.query\n",
    "            \n",
    "            if question_type in ['when', 'what']:\n",
    "                if not isinstance(result, Literal):\n",
    "                    continue\n",
    "\n",
    "            # print(type(result))\n",
    "            print(f\"Answer: {result} (from Graph)\")\n",
    "            query_answered = True\n",
    "            break\n",
    "\n",
    "    if not query_answered:\n",
    "        print(\"Could not find answer in graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the genre of Good Neighbors?\n",
      "{'genre': {'type': None, 'matches': ['http://www.wikidata.org/prop/direct/P136', 'http://www.wikidata.org/entity/Q483394']}, 'Good Neighbors': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q3110682']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q3110682', 'http://www.wikidata.org/entity/Q483394'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P136'}\n",
      "Answer: art film (from Graph)\n",
      "\n",
      "Who directed Apocalypse Now?\n",
      "{'directed': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q1162163', 'http://www.wikidata.org/entity/Q43229', 'http://www.wikidata.org/entity/Q81096', 'http://www.wikidata.org/prop/direct/P57', 'http://www.wikidata.org/entity/Q1251441']}, 'Apocalypse': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q60964254']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q1162163', 'http://www.wikidata.org/entity/Q60964254', 'http://www.wikidata.org/entity/Q43229', 'http://www.wikidata.org/entity/Q81096', 'http://www.wikidata.org/entity/Q1251441'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P57'}\n",
      "Answer: Isabelle Clarke (from Graph)\n",
      "\n",
      "Who is the director of Star Wars: Episode VI - Return of the Jedi?\n",
      "{'director': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q1162163', 'http://www.wikidata.org/prop/direct/P57']}, 'Star Wars: Episode VI - Return of the Jedi': {'type': None, 'matches': []}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q1162163'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P57'}\n",
      "Could not find answer in graph\n",
      "\n",
      "Who is the screenwriter of The Masked Gang: Cyprus?\n",
      "{'screenwriter': {'type': None, 'matches': ['http://www.wikidata.org/prop/direct/P58', 'http://www.wikidata.org/entity/Q28389']}, 'The Masked Gang: Cyprus': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q7750525']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q7750525', 'http://www.wikidata.org/entity/Q28389'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P58'}\n",
      "Could not find answer in graph\n",
      "\n",
      "When was The Godfather released?\n",
      "{'released': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q28869365', 'http://www.wikidata.org/prop/direct/P123', 'http://www.wikidata.org/entity/Q2085381', 'http://www.wikidata.org/entity/Q2979', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/prop/direct/P577', 'http://www.wikidata.org/entity/Q24238946', 'http://www.wikidata.org/entity/Q12334861', 'http://www.wikidata.org/entity/Q2031291']}, 'The Godfather': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q1139696']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q28869365', 'http://www.wikidata.org/entity/Q2085381', 'http://www.wikidata.org/entity/Q2979', 'http://www.wikidata.org/entity/Q1139696', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/entity/Q24238946', 'http://www.wikidata.org/entity/Q12334861', 'http://www.wikidata.org/entity/Q2031291'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P577', 'http://www.wikidata.org/prop/direct/P123'}\n",
      "Answer: 2006-03-21 (from Graph)\n",
      "\n",
      "Who is the producer of Inception?\n",
      "{'producer': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q47541952']}, 'Inception': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q3797611']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q47541952', 'http://www.wikidata.org/entity/Q3797611'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "Who composed the soundtrack for Jurassic Park?\n",
      "{'composed': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q2250012', 'http://www.wikidata.org/entity/Q36180', 'http://www.wikidata.org/entity/Q1511382', 'http://www.wikidata.org/entity/Q36834']}, 'soundtrack': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q217199']}, 'Jurassic Park': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q17862144']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q36180', 'http://www.wikidata.org/entity/Q217199', 'http://www.wikidata.org/entity/Q1511382', 'http://www.wikidata.org/entity/Q17862144', 'http://www.wikidata.org/entity/Q2250012', 'http://www.wikidata.org/entity/Q36834'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "When was Pulp Fiction released?\n",
      "{'released': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q28869365', 'http://www.wikidata.org/prop/direct/P123', 'http://www.wikidata.org/entity/Q2085381', 'http://www.wikidata.org/entity/Q2979', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/prop/direct/P577', 'http://www.wikidata.org/entity/Q24238946', 'http://www.wikidata.org/entity/Q12334861', 'http://www.wikidata.org/entity/Q2031291']}, 'Pulp Fiction': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q104123']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q28869365', 'http://www.wikidata.org/entity/Q2085381', 'http://www.wikidata.org/entity/Q2979', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/entity/Q24238946', 'http://www.wikidata.org/entity/Q12334861', 'http://www.wikidata.org/entity/Q104123', 'http://www.wikidata.org/entity/Q2031291'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P577', 'http://www.wikidata.org/prop/direct/P123'}\n",
      "Answer: 1994-05-21 (from Graph)\n",
      "\n",
      "Who played the lead role in The Matrix?\n",
      "{'played': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q222749', 'http://www.wikidata.org/entity/Q11422', 'http://www.wikidata.org/entity/Q1150958', 'http://www.wikidata.org/entity/Q33999', 'http://www.wikidata.org/entity/Q184872']}, 'lead role': {'type': None, 'matches': []}, 'The Matrix': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q83495']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q222749', 'http://www.wikidata.org/entity/Q11422', 'http://www.wikidata.org/entity/Q1150958', 'http://www.wikidata.org/entity/Q33999', 'http://www.wikidata.org/entity/Q184872', 'http://www.wikidata.org/entity/Q83495'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "Who directed Blade Runner 2049?\n",
      "{'directed': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q1162163', 'http://www.wikidata.org/entity/Q43229', 'http://www.wikidata.org/entity/Q81096', 'http://www.wikidata.org/prop/direct/P57', 'http://www.wikidata.org/entity/Q1251441']}, 'Blade Runner 2049': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q21500755']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q1162163', 'http://www.wikidata.org/entity/Q43229', 'http://www.wikidata.org/entity/Q81096', 'http://www.wikidata.org/entity/Q21500755', 'http://www.wikidata.org/entity/Q1251441'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P57'}\n",
      "Answer: Denis Villeneuve (from Graph)\n",
      "\n",
      "What is the running time of The Shawshank Redemption?\n",
      "{'running time': {'type': None, 'matches': []}, 'The Shawshank Redemption': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q172241']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q172241'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "Who was the cinematographer for Mad Max: Fury Road?\n",
      "{'cinematographer': {'type': None, 'matches': []}, 'Mad Max: Fury Road': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q1757288']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q1757288'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "When did Titanic premiere?\n",
      "{'did': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q35140', 'http://www.wikidata.org/entity/Q10354783']}, 'Titanic premiere': {'type': None, 'matches': []}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q35140', 'http://www.wikidata.org/entity/Q10354783'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "Who wrote the screenplay for The Social Network?\n",
      "{'wrote': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q2250012', 'http://www.wikidata.org/entity/Q36180', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/entity/Q36834']}, 'screenplay': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q103076']}, 'The Social Network': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q185888']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q36180', 'http://www.wikidata.org/entity/Q185888', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/entity/Q103076', 'http://www.wikidata.org/entity/Q2250012', 'http://www.wikidata.org/entity/Q36834'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "What is the box office gross of Avatar?\n",
      "{'box office gross': {'type': None, 'matches': []}, 'Avatar': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q24871']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q24871'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "Who edited the movie Parasite?\n",
      "{'edited': {'type': 'VERB', 'matches': []}, 'movie Parasite': {'type': None, 'matches': []}}\n",
      "Identified Items: set()\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "What is the budget of Halloween?\n",
      "{'budget': {'type': None, 'matches': []}, 'Halloween': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q20666646']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q20666646'}\n",
      "Identified Predicates: set()\n",
      "Could not find answer in graph\n",
      "\n",
      "Who starred as the main character in Forrest Gump?\n",
      "{'starred': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/P161', 'http://www.wikidata.org/entity/Q15982595', 'http://www.wikidata.org/prop/direct/P161']}, 'main character': {'type': None, 'matches': []}, 'Forrest Gump': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q134773']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q134773', 'http://www.wikidata.org/entity/Q15982595'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P161'}\n",
      "Answer: Kurt Russell (from Graph)\n",
      "\n",
      "When was Interstellar first released?\n",
      "{'released': {'type': 'VERB', 'matches': ['http://www.wikidata.org/entity/Q28869365', 'http://www.wikidata.org/prop/direct/P123', 'http://www.wikidata.org/entity/Q2085381', 'http://www.wikidata.org/entity/Q2979', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/prop/direct/P577', 'http://www.wikidata.org/entity/Q24238946', 'http://www.wikidata.org/entity/Q12334861', 'http://www.wikidata.org/entity/Q2031291']}, 'Interstellar': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q13417189']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q28869365', 'http://www.wikidata.org/entity/Q2085381', 'http://www.wikidata.org/entity/Q2979', 'http://www.wikidata.org/entity/Q732577', 'http://www.wikidata.org/entity/Q24238946', 'http://www.wikidata.org/entity/Q12334861', 'http://www.wikidata.org/entity/Q13417189', 'http://www.wikidata.org/entity/Q2031291'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P577', 'http://www.wikidata.org/prop/direct/P123'}\n",
      "Answer: 2014-10-26 (from Graph)\n",
      "\n",
      "Who is the production designer of Dune (2021)?\n",
      "{'production designer': {'type': None, 'matches': ['http://www.wikidata.org/prop/direct/P2554']}, 'Dune ( 2021': {'type': None, 'matches': []}}\n",
      "Identified Items: set()\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P2554'}\n",
      "Could not find answer in graph\n",
      "\n",
      "Who is the production designer of Dune?\n",
      "{'production designer': {'type': None, 'matches': ['http://www.wikidata.org/prop/direct/P2554']}, 'Dune': {'type': None, 'matches': ['http://www.wikidata.org/entity/Q18011127']}}\n",
      "Identified Items: {'http://www.wikidata.org/entity/Q18011127'}\n",
      "Identified Predicates: {'http://www.wikidata.org/prop/direct/P2554'}\n",
      "Could not find answer in graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in TEST_QUESTIONS:\n",
    "    print(question)\n",
    "    answer_factual(question)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
